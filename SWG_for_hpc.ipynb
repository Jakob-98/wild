{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from operator import itemgetter \n",
    "from itertools import groupby\n",
    "from os.path import exists\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = './data\\SWG\\swg_camera_traps.bounding_boxes.with_species\\swg_camera_traps.bounding_boxes.with_species.json'\n",
    "# base_url = \"https://lilablobssc.blob.core.windows.net/swg-camera-traps/\"\n",
    "# downloader = {'sas_url': 'https://lilablobssc.blob.core.windows.net/swg-camera-traps',\n",
    "#                 'filenames' : [] }\n",
    "lila_local_base = r'c:\\temp\\lila'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metadata_path) as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(d['images'])):\n",
    "    d['images'][i]['image_id'] = d['images'][i].pop('id')\n",
    "\n",
    "my_id = itemgetter('image_id')\n",
    "meta_anno = []\n",
    "\n",
    "for k, v in groupby(sorted((d['annotations'] + d['images']), key=my_id), key=my_id):\n",
    "    meta_anno.append({key:val for d in v for key, val in d.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of private ids: 1039\n",
      "number of corrupt ids: 0\n",
      "number of images removed based on cats and keyerror: 8\n"
     ]
    }
   ],
   "source": [
    "private_ids = set()\n",
    "for idx, image in enumerate(meta_anno):\n",
    "    if 'private' in image['file_name']:\n",
    "        private_ids.add(image['image_id'])\n",
    "print('number of private ids: {}'.format(len(private_ids)))\n",
    "meta_anno = [img for img in meta_anno if img.get('image_id') not in private_ids]\n",
    "\n",
    "\n",
    "corrupt_ids = set()\n",
    "for idx, image in enumerate(meta_anno):\n",
    "    if image['corrupt']:\n",
    "        corrupt_ids.add(image['image_id'])\n",
    "meta_anno = [img for img in meta_anno if img.get('image_id') not in corrupt_ids]\n",
    "print('number of corrupt ids: {}'.format(len(corrupt_ids)))\n",
    "\n",
    "\n",
    "category_remove_ids = set()\n",
    "for idx, image in enumerate(meta_anno):\n",
    "    try:\n",
    "        if image['category_id'] in (1,2): # tags 'ignore' and 'blurred' removed.\n",
    "            category_remove_ids.add(image['image_id'])\n",
    "    except KeyError: \n",
    "            category_remove_ids.add(image['image_id'])\n",
    "meta_anno = [img for img in meta_anno if img.get('image_id') not in category_remove_ids]\n",
    "print('number of images removed based on cats and keyerror: {}'.format(len(category_remove_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_species():\n",
    "    pass\n",
    "\n",
    "def filter_locations():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(d, remove_missing_id, n_empty= 1000, n_nempty=1000):\n",
    "    n_empty_images_per_dataset = n_empty\n",
    "    n_non_empty_images_per_dataset = n_nempty\n",
    "\n",
    "    category_id_to_name = {c['id']:c['name'] for c in d['categories']}\n",
    "    category_name_to_id = {c['name']:c['id'] for c in d['categories']}\n",
    "\n",
    "\n",
    "    human_category_id = category_name_to_id['human'] if 'human' in category_name_to_id.keys() else -1 # filter out humans\n",
    "\n",
    "\n",
    "    if 'empty' not in category_name_to_id:\n",
    "        print('Warning: no empty images available for {}'.format('dataset'))\n",
    "        empty_category_id = -1\n",
    "        empty_annotations = []\n",
    "        empty_annotations_to_download = []\n",
    "    else:\n",
    "        empty_category_id = category_name_to_id['empty']        \n",
    "        empty_annotations = [ann for ann in d['annotations'] if ann['category_id'] == empty_category_id and ann['image_id'] not in remove_missing_id]\n",
    "        empty_annotations_to_download = random.sample(empty_annotations, n_empty_images_per_dataset)        \n",
    "        \n",
    "    non_empty_annotations = [ann for ann in d['annotations'] if ann['category_id'] not in (empty_category_id, human_category_id) and ann['image_id'] not in remove_missing_id]\n",
    "\n",
    "    non_empty_annotations_to_download = random.sample(non_empty_annotations, n_non_empty_images_per_dataset)\n",
    "    annotations_to_download = empty_annotations_to_download + non_empty_annotations_to_download\n",
    "    image_ids_to_download = set([ann['image_id'] for ann in annotations_to_download])\n",
    "    assert len(image_ids_to_download) == len(set(image_ids_to_download))\n",
    "\n",
    "    images_to_download = []\n",
    "    for im in d['images']:\n",
    "        if im['image_id'] in image_ids_to_download:\n",
    "            images_to_download.append(im)\n",
    "    assert len(images_to_download) == len(image_ids_to_download)\n",
    "    \n",
    "    return images_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_download = gen_dataset(d, [-1], 10, 10)\n",
    "train, validate, test = np.split(images_to_download, [int(.8*len(images_to_download)), int(.9*len(images_to_download))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpaths = {}\n",
    "for dataset, setname in zip((train, validate, test), (\"train\", \"val\", \"test\")):\n",
    "    sas_url =  'https://lilablobssc.blob.core.windows.net/swg-camera-traps'\n",
    "    filenames = []\n",
    "    for im in dataset:\n",
    "        filenames = [im['file_name'] for im in dataset] # if im['id'] in image_ids_of_interest]\n",
    "\n",
    "\n",
    "    if '?' in sas_url:\n",
    "        base_url = sas_url.split('?')[0]        \n",
    "        sas_token = sas_url.split('?')[1]\n",
    "        assert not sas_token.startswith('?')\n",
    "    else:\n",
    "        sas_token = ''\n",
    "        base_url = sas_url\n",
    "        \n",
    "    assert not base_url.endswith('/')\n",
    "\n",
    "    p = urlparse(base_url)\n",
    "    account_path = p.scheme + '://' + p.netloc\n",
    "    assert account_path == 'https://lilablobssc.blob.core.windows.net'\n",
    "\n",
    "    container_and_folder = p.path[1:]\n",
    "    \n",
    "    if len(container_and_folder.split('/')) == 2:\n",
    "        container_name = container_and_folder.split('/')[0]\n",
    "        folder = container_and_folder.split('/',1)[1]\n",
    "        filenames = [folder + '/' + s for s in filenames]\n",
    "    else: \n",
    "        assert(len(container_and_folder.split('/')) == 1)\n",
    "        container_name = container_and_folder\n",
    "\n",
    "    container_sas_url = account_path + '/' + container_name\n",
    "    if len(sas_token) > 0:\n",
    "        container_sas_url += '?' + sas_token\n",
    "\n",
    "    output_dir = os.path.join(lila_local_base, setname)\n",
    "    setpaths[setname] = output_dir\n",
    "    os.makedirs(output_dir,exist_ok=True)\n",
    "\n",
    "    # The container name will be included because it's part of the file name\n",
    "    container_output_dir = output_dir # os.path.join(output_dir,container_name)\n",
    "\n",
    "    os.makedirs(container_output_dir,exist_ok=True)\n",
    "\n",
    "    # Write out a list of files, and use the azcopy \"list-of-files\" option to download those files\n",
    "    # this azcopy feature is unofficially documented at https://github.com/Azure/azure-storage-azcopy/wiki/Listing-specific-files-to-transfer\n",
    "    az_filename = os.path.join(output_dir, 'filenames_{}.txt'.format('TRAIN'.lower().replace(' ','_')))\n",
    "    with open(az_filename, 'w') as f:\n",
    "        for fn in filenames:\n",
    "            f.write(fn.replace('\\\\','/') + '\\n')\n",
    "            \n",
    "    cmd = 'azcopy cp \"{0}\" \"{1}\" --list-of-files \"{2}\"'.format(\n",
    "            container_sas_url, container_output_dir, az_filename)            \n",
    "\n",
    "    # import clipboard; clipboard.copy(cmd)\n",
    "\n",
    "    os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in setpaths.values():\n",
    "    for f in glob.glob(p + '\\**\\**\\**\\**.jpg', recursive=True):\n",
    "        fnew = f[f.find('public'):].replace('\\\\','-')\n",
    "        try:\n",
    "            shutil.move(f, p + '/' + fnew)\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\public\\\\vietnam\\\\loc_0806\\\\2015\\\\10\\\\image_00056.jpg'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"c:\\temp\\lila\\val\\swg-camera-traps\\public\\vietnam\\loc_0806\\2015\\10\\image_00056.jpg\"\n",
    "\n",
    "path[path.find(r'\\public'):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\temp\\\\lila\\\\train'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 'c:\\\\temp\\\\lila\\\\train',\n",
       " 'val': 'c:\\\\temp\\\\lila\\\\val',\n",
       " 'test': 'c:\\\\temp\\\\lila\\\\test'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(n, decimals=0):\n",
    "    multiplier = 10 ** decimals\n",
    "    return int(n * multiplier) / multiplier\n",
    "\n",
    "\n",
    "def createLabelsSingle(imageList, basedir, labeldirname, metadata_full):\n",
    "    # For single objects only\n",
    "\n",
    "    ids = [i.get('id') for i in imageList]\n",
    "    # generate lookup for bbox and category id based on image id\n",
    "\n",
    "\n",
    "    print(\"!WARNING: hardcoded fix for islands dataset\")\n",
    "\n",
    "    lookup = {}\n",
    "    for meta in metadata_full[\"annotations\"]:\n",
    "        if meta[\"image_id\"] not in ids: continue\n",
    "\n",
    "        bb = [0, 0, 1919, 1079] #TODO this is hardcoded fix/default for the islands dataset \n",
    "\n",
    "        try:\n",
    "            bb = meta['bbox']\n",
    "        except KeyError:\n",
    "            if meta['category_id'] != 0:\n",
    "                raise KeyError('Keyerror on boundingbox but not an empty image!')\n",
    "\n",
    "        lookup[meta['image_id']] = {\"bbox\": bb, \"category_id\": meta[\"category_id\"]}\n",
    "\n",
    "\n",
    "    for im in imageList:\n",
    "\n",
    "        ann = lookup.get(im['image_id'])\n",
    "\n",
    "        dw = 1. / im['width']\n",
    "        dh = 1. / im['height']\n",
    "        \n",
    "        \n",
    "        filename = im['file_name'].replace(\".jpg\", \".txt\").replace(\"/\", \"-\")\n",
    "        # print(Path(basedir).parent.__str__() + \"/labels/\" + labeldirname + filename, \"a\")\n",
    "        with open(str(basedir) + \"/labels/\" + labeldirname + filename, \"a\") as myfile:\n",
    "            xmin = ann[\"bbox\"][0]\n",
    "            ymin = ann[\"bbox\"][1]\n",
    "            xmax = ann[\"bbox\"][2] + ann[\"bbox\"][0]\n",
    "            ymax = ann[\"bbox\"][3] + ann[\"bbox\"][1]\n",
    "            \n",
    "            x = (xmin + xmax)/2\n",
    "            y = (ymin + ymax)/2\n",
    "            \n",
    "            w = xmax - xmin\n",
    "            h = ymax-ymin\n",
    "            \n",
    "            x = x * dw\n",
    "            w = w * dw\n",
    "            y = y * dh\n",
    "            h = h * dh\n",
    "            \n",
    "            mystring = str(str(ann['category_id']) + \" \" + str(truncate(x, 7)) + \" \" + str(truncate(y, 7)) + \" \" + str(truncate(w, 7)) + \" \" + str(truncate(h, 7)))\n",
    "            myfile.write(mystring)\n",
    "            myfile.write(\"\\n\")\n",
    "\n",
    "        myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!WARNING: hardcoded fix for islands dataset\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\temp\\\\lila/labels/train/public-lao-loc_0051-2018-04-image_00523.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\wild\\SWG_for_hpc.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/wild/SWG_for_hpc.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m dataset, setname \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m((train, validate, test), (\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/wild/SWG_for_hpc.ipynb#ch0000011?line=1'>2</a>\u001b[0m     setpath \u001b[39m=\u001b[39m setpaths\u001b[39m.\u001b[39mget(setname) \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/wild/SWG_for_hpc.ipynb#ch0000011?line=2'>3</a>\u001b[0m     createLabelsSingle(train, Path(setpath)\u001b[39m.\u001b[39;49mparent, \u001b[39m'\u001b[39;49m\u001b[39mtrain/\u001b[39;49m\u001b[39m'\u001b[39;49m, d)\n",
      "\u001b[1;32mc:\\Projects\\wild\\SWG_for_hpc.ipynb Cell 10'\u001b[0m in \u001b[0;36mcreateLabelsSingle\u001b[1;34m(imageList, basedir, labeldirname, metadata_full)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/SWG_for_hpc.ipynb#ch0000010?line=37'>38</a>\u001b[0m filename \u001b[39m=\u001b[39m im[\u001b[39m'\u001b[39m\u001b[39mfile_name\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/SWG_for_hpc.ipynb#ch0000010?line=38'>39</a>\u001b[0m \u001b[39m# print(Path(basedir).parent.__str__() + \"/labels/\" + labeldirname + filename, \"a\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/wild/SWG_for_hpc.ipynb#ch0000010?line=39'>40</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mstr\u001b[39;49m(basedir) \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m/labels/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m labeldirname \u001b[39m+\u001b[39;49m filename, \u001b[39m\"\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m myfile:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/SWG_for_hpc.ipynb#ch0000010?line=40'>41</a>\u001b[0m     xmin \u001b[39m=\u001b[39m ann[\u001b[39m\"\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/SWG_for_hpc.ipynb#ch0000010?line=41'>42</a>\u001b[0m     ymin \u001b[39m=\u001b[39m ann[\u001b[39m\"\u001b[39m\u001b[39mbbox\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m1\u001b[39m]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\temp\\\\lila/labels/train/public-lao-loc_0051-2018-04-image_00523.txt'"
     ]
    }
   ],
   "source": [
    "for dataset, setname in zip((train, validate, test), (\"train\", \"val\", \"test\")):\n",
    "    setpath = setpaths.get(setname) \n",
    "    createLabelsSingle(train, Path(setpath).parent, 'train/', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/temp/lila')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(setpath).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wild",
   "language": "python",
   "name": "wild"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
