{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from operator import itemgetter \n",
    "from itertools import groupby\n",
    "from os.path import exists\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = './data\\SWG\\swg_camera_traps.bounding_boxes.with_species\\swg_camera_traps.bounding_boxes.with_species.json'\n",
    "# base_url = \"https://lilablobssc.blob.core.windows.net/swg-camera-traps/\"\n",
    "# downloader = {'sas_url': 'https://lilablobssc.blob.core.windows.net/swg-camera-traps',\n",
    "#                 'filenames' : [] }\n",
    "lila_local_base = r'c:\\temp\\lila\\images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EMPTY, NUM_NONEMPTY = 10, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(metadata_path) as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0, 'name': 'empty', 'count': 264755},\n",
       " {'id': 1, 'name': 'ignore', 'count': 177546},\n",
       " {'id': 2, 'name': 'blurred', 'count': 184620},\n",
       " {'id': 4, 'name': 'crab_eating_mongoose', 'count': 17305},\n",
       " {'id': 5, 'name': 'ferret_badger', 'count': 41274},\n",
       " {'id': 6, 'name': 'large_antlered_muntjac', 'count': 119774},\n",
       " {'id': 7, 'name': 'stump_tailed_macaque', 'count': 73543},\n",
       " {'id': 8, 'name': 'unidentified_macaque', 'count': 1508},\n",
       " {'id': 9, 'name': 'unidentified_muntjac', 'count': 9604},\n",
       " {'id': 10, 'name': 'unidentified_small_mammal', 'count': 30376},\n",
       " {'id': 11, 'name': 'unidentified_squirrel', 'count': 8713},\n",
       " {'id': 12, 'name': 'eurasian_wild_pig', 'count': 234736},\n",
       " {'id': 13, 'name': 'problem', 'count': 288579},\n",
       " {'id': 14, 'name': 'common_palm_civet', 'count': 14589},\n",
       " {'id': 15, 'name': 'silver_pheasant', 'count': 16134},\n",
       " {'id': 16, 'name': 'unidentified_palm_civet', 'count': 769},\n",
       " {'id': 17, 'name': 'insect', 'count': 6818},\n",
       " {'id': 18, 'name': 'masked_palm_civet', 'count': 13022},\n",
       " {'id': 19, 'name': 'pig_tailed_macaque', 'count': 42546},\n",
       " {'id': 20, 'name': 'red_cheeked_squirrel', 'count': 40373},\n",
       " {'id': 21, 'name': 'roosevelts_muntjac_group', 'count': 60093},\n",
       " {'id': 22, 'name': 'sambar', 'count': 74459},\n",
       " {'id': 23, 'name': 'spotted_linsang', 'count': 3569},\n",
       " {'id': 24, 'name': 'unidentified_animal', 'count': 13288},\n",
       " {'id': 25, 'name': 'unidentified_bird', 'count': 40782},\n",
       " {'id': 26, 'name': 'unidentified_partridge', 'count': 11132},\n",
       " {'id': 27, 'name': 'unidentified_ungulates', 'count': 2262},\n",
       " {'id': 28, 'name': 'unidentified_murid', 'count': 98858},\n",
       " {'id': 29, 'name': 'red_junglefowl', 'count': 6649},\n",
       " {'id': 30, 'name': 'blue_pitta', 'count': 107},\n",
       " {'id': 31, 'name': 'pallass_squirrel', 'count': 5832},\n",
       " {'id': 32, 'name': 'yellow_throated_marten', 'count': 16375},\n",
       " {'id': 33, 'name': 'grey_peacock_pheasant', 'count': 7798},\n",
       " {'id': 34, 'name': 'white_crowned_forktail', 'count': 144},\n",
       " {'id': 35, 'name': 'emerald_dove', 'count': 268},\n",
       " {'id': 36, 'name': 'human', 'count': 3808},\n",
       " {'id': 37, 'name': 'unidentified_pitta', 'count': 171},\n",
       " {'id': 38, 'name': 'laughingthrush', 'count': 9},\n",
       " {'id': 39, 'name': 'asiatic_brush_tailed_porcupine', 'count': 13227},\n",
       " {'id': 40, 'name': 'large_indian_civet', 'count': 1357},\n",
       " {'id': 41, 'name': 'unidentified_otter', 'count': 112},\n",
       " {'id': 42, 'name': 'unidentified_owl', 'count': 32},\n",
       " {'id': 43, 'name': 'white-winged_magpie', 'count': 24},\n",
       " {'id': 44, 'name': 'japanese_thrush', 'count': 85},\n",
       " {'id': 45, 'name': 'orange_headed_thrush', 'count': 310},\n",
       " {'id': 46, 'name': 'scaly_thrush', 'count': 735},\n",
       " {'id': 47, 'name': 'unidentified_mammal', 'count': 4347},\n",
       " {'id': 48, 'name': 'gray_laughingthrush', 'count': 12},\n",
       " {'id': 49, 'name': 'eurasian_woodcock', 'count': 27},\n",
       " {'id': 50, 'name': 'red_collared_woodpecker', 'count': 18},\n",
       " {'id': 51, 'name': 'blue_whistling_thrush', 'count': 2903},\n",
       " {'id': 52, 'name': 'large_scimitar_babbler', 'count': 25},\n",
       " {'id': 53, 'name': 'rufous_cheeked_laughingthrush', 'count': 479},\n",
       " {'id': 54, 'name': 'chinese_serow', 'count': 19920},\n",
       " {'id': 55, 'name': 'gibbon', 'count': 9},\n",
       " {'id': 56, 'name': 'red_shanked_douc', 'count': 1229},\n",
       " {'id': 57, 'name': 'annamite_striped_rabbit', 'count': 4943},\n",
       " {'id': 58, 'name': 'blue_fronted_robin', 'count': 21},\n",
       " {'id': 59, 'name': 'orange_breasted_trogon', 'count': 6},\n",
       " {'id': 60, 'name': 'chevrotain', 'count': 3918},\n",
       " {'id': 61, 'name': 'unidentified_pheasant', 'count': 75},\n",
       " {'id': 62, 'name': 'bar_bellied_pitta', 'count': 44},\n",
       " {'id': 63, 'name': 'domestic_dog', 'count': 743},\n",
       " {'id': 64, 'name': 'malayan_porcupine', 'count': 7864},\n",
       " {'id': 65, 'name': 'assam_or_rhesus_macaque', 'count': 12222},\n",
       " {'id': 66, 'name': 'unidentified_bat', 'count': 317},\n",
       " {'id': 67, 'name': 'indochinese_green_magpie', 'count': 3},\n",
       " {'id': 68, 'name': 'common_green_magpie', 'count': 1},\n",
       " {'id': 69, 'name': 'francois_langur', 'count': 2},\n",
       " {'id': 70, 'name': 'leopard_cat', 'count': 266},\n",
       " {'id': 71, 'name': 'binturong', 'count': 49},\n",
       " {'id': 72, 'name': 'hog_badger', 'count': 352},\n",
       " {'id': 73, 'name': 'crested_argus', 'count': 446},\n",
       " {'id': 74, 'name': 'pangolin', 'count': 351},\n",
       " {'id': 75, 'name': 'bamboo_rat', 'count': 87},\n",
       " {'id': 76, 'name': 'asiatic_black_bear', 'count': 1211},\n",
       " {'id': 77, 'name': 'mountain_hawk_eagle', 'count': 3},\n",
       " {'id': 78, 'name': 'unidentified_bear', 'count': 96},\n",
       " {'id': 79, 'name': 'unidentified_weasel', 'count': 513},\n",
       " {'id': 80, 'name': 'northern_treeshrew', 'count': 4779},\n",
       " {'id': 81, 'name': 'bengal_monitor', 'count': 11},\n",
       " {'id': 82, 'name': 'black_giant_squirrel', 'count': 229},\n",
       " {'id': 83, 'name': 'sun_bear', 'count': 295},\n",
       " {'id': 84, 'name': 'marbled_cat', 'count': 51},\n",
       " {'id': 85, 'name': 'unidentified_striped_squirrel', 'count': 63},\n",
       " {'id': 86, 'name': 'hatinh_langur', 'count': 26},\n",
       " {'id': 87, 'name': 'unidentified_turtles', 'count': 16},\n",
       " {'id': 88, 'name': 'red_muntjac', 'count': 4960},\n",
       " {'id': 89, 'name': 'phayres_langur', 'count': 105},\n",
       " {'id': 90, 'name': 'giant_flying_squirrel', 'count': 534},\n",
       " {'id': 91, 'name': 'rufous_necked_hornbill', 'count': 6},\n",
       " {'id': 92, 'name': 'golden_cat', 'count': 15},\n",
       " {'id': 93, 'name': 'owstons_civet', 'count': 210},\n",
       " {'id': 94, 'name': 'invertebrate', 'count': 3},\n",
       " {'id': 95, 'name': 'chinese serow', 'count': 12820},\n",
       " {'id': 96, 'name': 'unidentified_lizard', 'count': 114},\n",
       " {'id': 97, 'name': 'macaque_not_stump_tailed', 'count': 2269},\n",
       " {'id': 98, 'name': 'unidentified_small_animal', 'count': 917},\n",
       " {'id': 99, 'name': 'yellow_bellied_weasel', 'count': 15},\n",
       " {'id': 100, 'name': 'brown_wood_owl', 'count': 415},\n",
       " {'id': 101, 'name': 'necklaced_laughingthrush_sp', 'count': 442},\n",
       " {'id': 102, 'name': 'mountain_imperial_pigeon', 'count': 34},\n",
       " {'id': 103, 'name': 'rufous_eared_laughingthrush', 'count': 4},\n",
       " {'id': 104, 'name': 'lesser_yellownape', 'count': 9},\n",
       " {'id': 105, 'name': 'red_tailed_laughingthrush', 'count': 15},\n",
       " {'id': 106, 'name': 'flying_squirrel', 'count': 44},\n",
       " {'id': 107, 'name': 'siberian_thrush', 'count': 283},\n",
       " {'id': 108, 'name': 'asian_fairy_bluebird', 'count': 2},\n",
       " {'id': 109, 'name': 'forktail_sp', 'count': 15},\n",
       " {'id': 110, 'name': 'striated_heron', 'count': 3},\n",
       " {'id': 111, 'name': 'crested_serpent_eagle', 'count': 186},\n",
       " {'id': 112, 'name': 'black_throated_laughingthrush', 'count': 15},\n",
       " {'id': 113, 'name': 'golden_babbler', 'count': 14},\n",
       " {'id': 114, 'name': 'back_striped_weasel', 'count': 13},\n",
       " {'id': 115, 'name': 'barred_cuckoo_dove', 'count': 10},\n",
       " {'id': 116, 'name': 'unidentified_snake', 'count': 9},\n",
       " {'id': 117, 'name': 'white_tailed_robin', 'count': 9},\n",
       " {'id': 118, 'name': 'eyebrowed_thrush', 'count': 106},\n",
       " {'id': 119, 'name': 'silver_eared_mesia', 'count': 5},\n",
       " {'id': 120, 'name': 'grey_headed_canary_flycatcher', 'count': 14},\n",
       " {'id': 121, 'name': 'vehicle'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(d['images'])):\n",
    "    d['images'][i]['image_id'] = d['images'][i].pop('id')\n",
    "\n",
    "my_id = itemgetter('image_id')\n",
    "meta_anno = []\n",
    "\n",
    "for k, v in groupby(sorted((d['annotations'] + d['images']), key=my_id), key=my_id):\n",
    "    meta_anno.append({key:val for d in v for key, val in d.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of private ids: 1039\n",
      "number of corrupt ids: 0\n",
      "number of images removed based on cats and keyerror: 8\n"
     ]
    }
   ],
   "source": [
    "private_ids = set()\n",
    "for idx, image in enumerate(meta_anno):\n",
    "    if 'private' in image['file_name']:\n",
    "        private_ids.add(image['image_id'])\n",
    "print('number of private ids: {}'.format(len(private_ids)))\n",
    "meta_anno = [img for img in meta_anno if img.get('image_id') not in private_ids]\n",
    "\n",
    "\n",
    "corrupt_ids = set()\n",
    "for idx, image in enumerate(meta_anno):\n",
    "    if image['corrupt']:\n",
    "        corrupt_ids.add(image['image_id'])\n",
    "meta_anno = [img for img in meta_anno if img.get('image_id') not in corrupt_ids]\n",
    "print('number of corrupt ids: {}'.format(len(corrupt_ids)))\n",
    "\n",
    "\n",
    "category_remove_ids = set()\n",
    "for idx, image in enumerate(meta_anno):\n",
    "    try:\n",
    "        if image['category_id'] in (1,2): # tags 'ignore' and 'blurred' removed.\n",
    "            category_remove_ids.add(image['image_id'])\n",
    "    except KeyError: \n",
    "            category_remove_ids.add(image['image_id'])\n",
    "meta_anno = [img for img in meta_anno if img.get('image_id') not in category_remove_ids]\n",
    "print('number of images removed based on cats and keyerror: {}'.format(len(category_remove_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in d['annotations'] if i.get('category_id') == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datetime': '2017-12-17 13:49:18+00:00',\n",
       " 'file_name': 'public/lao/loc_0002/2017/12/image_00042.jpg',\n",
       " 'seq_id': 'e227334e-8c29-11eb-8edb-000d3a74c7de',\n",
       " 'frame_num': 0,\n",
       " 'seq_num_frames': 3,\n",
       " 'location': 'loc_0002',\n",
       " 'width': 3264,\n",
       " 'height': 2448,\n",
       " 'corrupt': False,\n",
       " 'image_id': 'c7d9493c-8c29-11eb-8037-000d3a74c7de'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133837"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d['annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_species():\n",
    "    pass\n",
    "\n",
    "def filter_locations():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(d, remove_missing_id, n_empty= 1000, n_nempty=1000):\n",
    "    n_empty_images_per_dataset = n_empty\n",
    "    n_non_empty_images_per_dataset = n_nempty\n",
    "\n",
    "    category_id_to_name = {c['id']:c['name'] for c in d['categories']}\n",
    "    category_name_to_id = {c['name']:c['id'] for c in d['categories']}\n",
    "\n",
    "\n",
    "    human_category_id = category_name_to_id['human'] if 'human' in category_name_to_id.keys() else -1 # filter out humans\n",
    "\n",
    "\n",
    "    if 'empty' not in category_name_to_id:\n",
    "        print('Warning: no empty images available for {}'.format('dataset'))\n",
    "        empty_category_id = -1\n",
    "        empty_annotations = []\n",
    "        empty_annotations_to_download = []\n",
    "    else:\n",
    "        empty_category_id = category_name_to_id['empty']        \n",
    "        empty_annotations = [ann for ann in d['annotations'] if ann['category_id'] == empty_category_id and ann['image_id'] not in remove_missing_id]\n",
    "        empty_annotations_to_download = random.sample(empty_annotations, n_empty_images_per_dataset)        \n",
    "        \n",
    "    non_empty_annotations = [ann for ann in d['annotations'] if ann['category_id'] not in (empty_category_id, human_category_id) and ann['image_id'] not in remove_missing_id]\n",
    "\n",
    "    non_empty_annotations_to_download = random.sample(non_empty_annotations, n_non_empty_images_per_dataset)\n",
    "    annotations_to_download = empty_annotations_to_download + non_empty_annotations_to_download\n",
    "    image_ids_to_download = set([ann['image_id'] for ann in annotations_to_download])\n",
    "    assert len(image_ids_to_download) == len(set(image_ids_to_download))\n",
    "\n",
    "    images_to_download = []\n",
    "    for im in d['images']:\n",
    "        if im['image_id'] in image_ids_to_download:\n",
    "            images_to_download.append(im)\n",
    "    assert len(images_to_download) == len(image_ids_to_download)\n",
    "    \n",
    "    return images_to_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_to_download = gen_dataset(d, [-1], NUM_EMPTY, NUM_NONEMPTY)\n",
    "train, validate, test = np.split(images_to_download, [int(.8*len(images_to_download)), int(.9*len(images_to_download))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "setpaths = {}\n",
    "for dataset, setname in zip((train, validate, test), (\"train\", \"val\", \"test\")):\n",
    "    sas_url =  'https://lilablobssc.blob.core.windows.net/swg-camera-traps'\n",
    "    filenames = []\n",
    "    for im in dataset:\n",
    "        filenames = [im['file_name'] for im in dataset] # if im['id'] in image_ids_of_interest]\n",
    "\n",
    "\n",
    "    if '?' in sas_url:\n",
    "        base_url = sas_url.split('?')[0]        \n",
    "        sas_token = sas_url.split('?')[1]\n",
    "        assert not sas_token.startswith('?')\n",
    "    else:\n",
    "        sas_token = ''\n",
    "        base_url = sas_url\n",
    "        \n",
    "    assert not base_url.endswith('/')\n",
    "\n",
    "    p = urlparse(base_url)\n",
    "    account_path = p.scheme + '://' + p.netloc\n",
    "    assert account_path == 'https://lilablobssc.blob.core.windows.net'\n",
    "\n",
    "    container_and_folder = p.path[1:]\n",
    "    \n",
    "    if len(container_and_folder.split('/')) == 2:\n",
    "        container_name = container_and_folder.split('/')[0]\n",
    "        folder = container_and_folder.split('/',1)[1]\n",
    "        filenames = [folder + '/' + s for s in filenames]\n",
    "    else: \n",
    "        assert(len(container_and_folder.split('/')) == 1)\n",
    "        container_name = container_and_folder\n",
    "\n",
    "    container_sas_url = account_path + '/' + container_name\n",
    "    if len(sas_token) > 0:\n",
    "        container_sas_url += '?' + sas_token\n",
    "\n",
    "    output_dir = os.path.join(lila_local_base, setname)\n",
    "    setpaths[setname] = output_dir\n",
    "    os.makedirs(output_dir,exist_ok=True)\n",
    "\n",
    "    # The container name will be included because it's part of the file name\n",
    "    container_output_dir = output_dir # os.path.join(output_dir,container_name)\n",
    "\n",
    "    os.makedirs(container_output_dir,exist_ok=True)\n",
    "\n",
    "    # Write out a list of files, and use the azcopy \"list-of-files\" option to download those files\n",
    "    # this azcopy feature is unofficially documented at https://github.com/Azure/azure-storage-azcopy/wiki/Listing-specific-files-to-transfer\n",
    "    az_filename = os.path.join(output_dir, 'filenames_{}.txt'.format('TRAIN'.lower().replace(' ','_')))\n",
    "    with open(az_filename, 'w') as f:\n",
    "        for fn in filenames:\n",
    "            f.write(fn.replace('\\\\','/') + '\\n')\n",
    "            \n",
    "    cmd = 'azcopy cp \"{0}\" \"{1}\" --list-of-files \"{2}\"'.format(\n",
    "            container_sas_url, container_output_dir, az_filename)            \n",
    "\n",
    "    # import clipboard; clipboard.copy(cmd)\n",
    "\n",
    "    os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 'c:\\\\temp\\\\lila\\\\images\\\\train',\n",
       " 'val': 'c:\\\\temp\\\\lila\\\\images\\\\val',\n",
       " 'test': 'c:\\\\temp\\\\lila\\\\images\\\\test'}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in setpaths.values():\n",
    "    for f in glob.glob(p + '\\**\\**\\**\\**.jpg', recursive=True):\n",
    "        fnew = f[f.find('public'):].replace('\\\\','-')\n",
    "        try:\n",
    "            shutil.move(f, p + '/' + fnew)\n",
    "        except FileNotFoundError:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate(n, decimals=0):\n",
    "    multiplier = 10 ** decimals\n",
    "    return int(n * multiplier) / multiplier\n",
    "\n",
    "\n",
    "def createLabelsSingle(imageList, basedir, labeldirname, metadata_full):\n",
    "    # For single objects only\n",
    "\n",
    "    basedir = basedir.parent\n",
    "    os.makedirs(str(basedir) + \"/labels/\" + labeldirname,exist_ok=True)\n",
    "\n",
    "    ids = [i.get('image_id') for i in imageList]\n",
    "    # generate lookup for bbox and category id based on image id\n",
    "\n",
    "\n",
    "    print(\"!WARNING: hardcoded fix for islands dataset\")\n",
    "\n",
    "    lookup = {}\n",
    "    for meta in metadata_full[\"annotations\"]:\n",
    "        if meta[\"image_id\"] not in ids: continue\n",
    "\n",
    "        bb = [0, 0, 1919, 1079] #TODO this is hardcoded fix/default for the islands dataset \n",
    "\n",
    "        try:\n",
    "            bb = meta['bbox']\n",
    "        except KeyError:\n",
    "            if meta['category_id'] != 0:\n",
    "                raise KeyError('Keyerror on boundingbox but not an empty image!')\n",
    "\n",
    "        lookup[meta['image_id']] = {\"bbox\": bb, \"category_id\": meta[\"category_id\"]}\n",
    "\n",
    "\n",
    "    for im in imageList:\n",
    "\n",
    "        ann = lookup.get(im['image_id'])\n",
    "\n",
    "        dw = 1. / im['width']\n",
    "        dh = 1. / im['height']\n",
    "        \n",
    "        \n",
    "        filename = im['file_name'].replace(\".jpg\", \".txt\").replace(\"/\", \"-\")\n",
    "        # print(Path(basedir).parent.__str__() + \"/labels/\" + labeldirname + filename, \"a\")\n",
    "        with open(str(basedir) + \"/labels/\" + labeldirname + filename, \"a\") as myfile:\n",
    "            xmin = ann[\"bbox\"][0]\n",
    "            ymin = ann[\"bbox\"][1]\n",
    "            xmax = ann[\"bbox\"][2] + ann[\"bbox\"][0]\n",
    "            ymax = ann[\"bbox\"][3] + ann[\"bbox\"][1]\n",
    "            \n",
    "            x = (xmin + xmax)/2\n",
    "            y = (ymin + ymax)/2\n",
    "            \n",
    "            w = xmax - xmin\n",
    "            h = ymax-ymin\n",
    "            \n",
    "            x = x * dw\n",
    "            w = w * dw\n",
    "            y = y * dh\n",
    "            h = h * dh\n",
    "            \n",
    "            mystring = str(str(ann['category_id']) + \" \" + str(truncate(x, 7)) + \" \" + str(truncate(y, 7)) + \" \" + str(truncate(w, 7)) + \" \" + str(truncate(h, 7)))\n",
    "            myfile.write(mystring)\n",
    "            myfile.write(\"\\n\")\n",
    "\n",
    "        myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!WARNING: hardcoded fix for islands dataset\n",
      "!WARNING: hardcoded fix for islands dataset\n",
      "!WARNING: hardcoded fix for islands dataset\n"
     ]
    }
   ],
   "source": [
    "for dataset, setname in zip((train, validate, test), (\"train\", \"val\", \"test\")):\n",
    "    setpath = setpaths.get(setname) \n",
    "    createLabelsSingle(dataset, Path(setpath).parent, setname + '/', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wild",
   "language": "python",
   "name": "wild"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
