wandb: Currently logged in as: jakobs. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.12.21
wandb: Run data is saved locally in /home/serlierj/test_batchscripts/ghostnet/ghostnet_seq_nohistlbp/wandb/run-20220802_183033-1u1s96x8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-hill-32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jakobs/uncategorized
wandb: üöÄ View run at https://wandb.ai/jakobs/uncategorized/runs/1u1s96x8
/home/serlierj/envs/wild/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/serlierj/envs/wild/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
/home/serlierj/envs/wild/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/serlierj/envs/wild/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:231: UserWarning: You called `self.log('confusion_matrix', ...)` in your `validation_epoch_end` but the value needs to be floating point. Converting it to torch.float32.
  f"You called `self.log({self.meta.name!r}, ...)` in your `{self.meta.fx}` but the value needs to"
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.001 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: \ 0.029 MB of 0.029 MB uploaded (0.000 MB deduped)wandb: | 0.029 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: / 0.029 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: - 0.038 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: \ 0.038 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: | 0.038 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: / 0.038 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: - 0.038 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: \ 0.038 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: | 0.038 MB of 0.036 MB uploaded (0.000 MB deduped)wandb: / 0.038 MB of 0.036 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:   class_0_precision ‚ñÅ
wandb:      class_0_recall ‚ñÅ
wandb:   class_1_precision ‚ñÅ
wandb:   class_2_precision ‚ñÅ
wandb:      class_2_recall ‚ñÅ
wandb:   class_3_precision ‚ñÅ
wandb:   class_4_precision ‚ñÅ
wandb:      class_4_recall ‚ñÅ
wandb:   class_5_precision ‚ñÅ
wandb:    confusion_matrix ‚ñÅ
wandb:               epoch ‚ñÅ
wandb: trainer/global_step ‚ñÅ
wandb:             val_acc ‚ñÅ
wandb:              val_f1 ‚ñÅ
wandb:            val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:   class_0_precision 0.77317
wandb:      class_0_recall 0.82653
wandb:   class_1_precision 0.0
wandb:      class_1_recall nan
wandb:   class_2_precision 0.60295
wandb:      class_2_recall 0.68828
wandb:   class_3_precision 0.0
wandb:      class_3_recall nan
wandb:   class_4_precision 0.86832
wandb:      class_4_recall 0.67636
wandb:   class_5_precision 0.0
wandb:      class_5_recall nan
wandb:    confusion_matrix 238.72223
wandb:               epoch 0
wandb: trainer/global_step 0
wandb:             val_acc 0.74366
wandb:              val_f1 0.74366
wandb:            val_loss 98.08857
wandb: 
wandb: Synced mild-hill-32: https://wandb.ai/jakobs/uncategorized/runs/1u1s96x8
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220802_183033-1u1s96x8/logs
