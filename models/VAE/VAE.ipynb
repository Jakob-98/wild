{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "import math\n",
    "import sys\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "from abc import abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Callable, Union, Any, TypeVar, Tuple\n",
    "# from torch import tensor as Tensor\n",
    "\n",
    "Tensor = TypeVar('torch.tensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseVAE(nn.Module):\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        super(BaseVAE, self).__init__()\n",
    "\n",
    "    def encode(self, input: Tensor) -> List[Tensor]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def decode(self, input: Tensor) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sample(self, batch_size:int, current_device: int, **kwargs) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, *inputs: Tensor) -> Tensor:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def loss_function(self, *inputs: Any, **kwargs) -> Tensor:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWAE(BaseVAE):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 latent_dim: int,\n",
    "                 hidden_dims: List = None,\n",
    "                 reg_weight: int = 100,\n",
    "                 wasserstein_deg: float= 2.,\n",
    "                 num_projections: int = 50,\n",
    "                 projection_dist: str = 'normal',\n",
    "                    **kwargs) -> None:\n",
    "        super(SWAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.reg_weight = reg_weight\n",
    "        self.p = wasserstein_deg\n",
    "        self.num_projections = num_projections\n",
    "        self.proj_dist = projection_dist\n",
    "\n",
    "        modules = []\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [32, 64, 128, 256, 512]\n",
    "\n",
    "        # Build Encoder\n",
    "        for h_dim in hidden_dims:\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, out_channels=h_dim,\n",
    "                              kernel_size= 3, stride= 2, padding  = 1),\n",
    "                    nn.BatchNorm2d(h_dim),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "            in_channels = h_dim\n",
    "\n",
    "        self.encoder = nn.Sequential(*modules)\n",
    "        self.fc_z = nn.Linear(hidden_dims[-1]*4, latent_dim)\n",
    "\n",
    "\n",
    "        # Build Decoder\n",
    "        modules = []\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dims[-1] * 4)\n",
    "\n",
    "        hidden_dims.reverse()\n",
    "\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            modules.append(\n",
    "                nn.Sequential(\n",
    "                    nn.ConvTranspose2d(hidden_dims[i],\n",
    "                                       hidden_dims[i + 1],\n",
    "                                       kernel_size=3,\n",
    "                                       stride = 2,\n",
    "                                       padding=1,\n",
    "                                       output_padding=1),\n",
    "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
    "                    nn.LeakyReLU())\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(*modules)\n",
    "\n",
    "        self.final_layer = nn.Sequential(\n",
    "                            nn.ConvTranspose2d(hidden_dims[-1],\n",
    "                                               hidden_dims[-1],\n",
    "                                               kernel_size=3,\n",
    "                                               stride=2,\n",
    "                                               padding=1,\n",
    "                                               output_padding=1),\n",
    "                            nn.BatchNorm2d(hidden_dims[-1]),\n",
    "                            nn.LeakyReLU(),\n",
    "                            nn.Conv2d(hidden_dims[-1], out_channels= 3,\n",
    "                                      kernel_size= 3, padding= 1),\n",
    "                            nn.Tanh())\n",
    "\n",
    "    def encode(self, input: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Encodes the input by passing through the encoder network\n",
    "        and returns the latent codes.\n",
    "        :param input: (Tensor) Input tensor to encoder [N x C x H x W]\n",
    "        :return: (Tensor) List of latent codes\n",
    "        \"\"\"\n",
    "        result = self.encoder(input)\n",
    "        result = torch.flatten(result, start_dim=1)\n",
    "\n",
    "        # Split the result into mu and var components\n",
    "        # of the latent Gaussian distribution\n",
    "        z = self.fc_z(result)\n",
    "        return z\n",
    "\n",
    "    def decode(self, z: Tensor) -> Tensor:\n",
    "        result = self.decoder_input(z)\n",
    "        result = result.view(-1, 512, 2, 2)\n",
    "        result = self.decoder(result)\n",
    "        result = self.final_layer(result)\n",
    "        return result\n",
    "\n",
    "    def forward(self, input: Tensor, **kwargs) -> List[Tensor]:\n",
    "        z = self.encode(input)\n",
    "        return  [self.decode(z), input, z]\n",
    "\n",
    "    def loss_function(self,\n",
    "                      *args,\n",
    "                      **kwargs) -> dict:\n",
    "        recons = args[0]\n",
    "        input = args[1]\n",
    "        z = args[2]\n",
    "\n",
    "        batch_size = input.size(0)\n",
    "        bias_corr = batch_size *  (batch_size - 1)\n",
    "        reg_weight = self.reg_weight / bias_corr\n",
    "\n",
    "        recons_loss_l2 = F.mse_loss(recons, input)\n",
    "        recons_loss_l1 = F.l1_loss(recons, input)\n",
    "\n",
    "        swd_loss = self.compute_swd(z, self.p, reg_weight)\n",
    "\n",
    "        loss = recons_loss_l2 + recons_loss_l1 + swd_loss\n",
    "        return {'loss': loss, 'Reconstruction_Loss':(recons_loss_l2 + recons_loss_l1), 'SWD': swd_loss}\n",
    "\n",
    "    def get_random_projections(self, latent_dim: int, num_samples: int) -> Tensor:\n",
    "        \"\"\"\n",
    "        Returns random samples from latent distribution's (Gaussian)\n",
    "        unit sphere for projecting the encoded samples and the\n",
    "        distribution samples.\n",
    "        :param latent_dim: (Int) Dimensionality of the latent space (D)\n",
    "        :param num_samples: (Int) Number of samples required (S)\n",
    "        :return: Random projections from the latent unit sphere\n",
    "        \"\"\"\n",
    "        if self.proj_dist == 'normal':\n",
    "            rand_samples = torch.randn(num_samples, latent_dim)\n",
    "        elif self.proj_dist == 'cauchy':\n",
    "            rand_samples = dist.Cauchy(torch.tensor([0.0]),\n",
    "                                       torch.tensor([1.0])).sample((num_samples, latent_dim)).squeeze()\n",
    "        else:\n",
    "            raise ValueError('Unknown projection distribution.')\n",
    "\n",
    "        rand_proj = rand_samples / rand_samples.norm(dim=1).view(-1,1)\n",
    "        return rand_proj # [S x D]\n",
    "\n",
    "\n",
    "    def compute_swd(self,\n",
    "                    z: Tensor,\n",
    "                    p: float,\n",
    "                    reg_weight: float) -> Tensor:\n",
    "        \"\"\"\n",
    "        Computes the Sliced Wasserstein Distance (SWD) - which consists of\n",
    "        randomly projecting the encoded and prior vectors and computing\n",
    "        their Wasserstein distance along those projections.\n",
    "        :param z: Latent samples # [N  x D]\n",
    "        :param p: Value for the p^th Wasserstein distance\n",
    "        :param reg_weight:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        prior_z = torch.randn_like(z) # [N x D]\n",
    "        device = z.device\n",
    "\n",
    "        proj_matrix = self.get_random_projections(self.latent_dim,\n",
    "                                                  num_samples=self.num_projections).transpose(0,1).to(device)\n",
    "\n",
    "        latent_projections = z.matmul(proj_matrix) # [N x S]\n",
    "        prior_projections = prior_z.matmul(proj_matrix) # [N x S]\n",
    "\n",
    "        # The Wasserstein distance is computed by sorting the two projections\n",
    "        # across the batches and computing their element-wise l2 distance\n",
    "        w_dist = torch.sort(latent_projections.t(), dim=1)[0] - \\\n",
    "                 torch.sort(prior_projections.t(), dim=1)[0]\n",
    "        w_dist = w_dist.pow(p)\n",
    "        return reg_weight * w_dist.mean()\n",
    "\n",
    "    def sample(self,\n",
    "               num_samples:int,\n",
    "               current_device: int, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Samples from the latent space and return the corresponding\n",
    "        image space map.\n",
    "        :param num_samples: (Int) Number of samples\n",
    "        :param current_device: (Int) Device to run the model\n",
    "        :return: (Tensor)\n",
    "        \"\"\"\n",
    "        z = torch.randn(num_samples,\n",
    "                        self.latent_dim)\n",
    "\n",
    "        z = z.to(current_device)\n",
    "\n",
    "        samples = self.decode(z)\n",
    "        return samples\n",
    "\n",
    "    def generate(self, x: Tensor, **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Given an input image x, returns the reconstructed image\n",
    "        :param x: (Tensor) [B x C x H x W]\n",
    "        :return: (Tensor) [B x C x H x W]\n",
    "        \"\"\"\n",
    "\n",
    "        return self.forward(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d488aad3bd47f31cc49211d239eea484ef57a3647b66c4c13e8e3612e9e7defd"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('wildsenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
