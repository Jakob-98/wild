{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.seed import seed_everything\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.utils as vutils\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple, Optional\n",
    "# from torch import tensor as Tensor\n",
    "\n",
    "Tensor = TypeVar('torch.tensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ena_local = 'C:/temp/ena/images/train5/'\n",
    "images = [os.path.split(i)[1] for i in glob.glob(ena_local + '/*.jpg', recursive=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('c:/temp/numpyfinal.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = 'C:\\Projects\\wild\\data\\ENA24\\ena24_public.json'\n",
    "with open(metadata_path) as f:\n",
    "    d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = {l['image_id']:  l['category_id'] for l in d['annotations'] if l['image_id'] in [i.split('.jpg')[0] for i in images]}\n",
    "feats = {image.split('.jpg')[0] : feat for image, feat in zip(images, data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENA6(Dataset):\n",
    "    def __init__(self, ids, cats, feats, transform):\n",
    "        self.ids = ids\n",
    "        self.cats = cats\n",
    "        self.feats = feats\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feats, cats = self.feats.get(index), self.cats.get(index)\n",
    "        feats, cats = self.transform(feats), self.transform(cats)\n",
    "        return feats, cats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(6, 1, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.MaxPool1d(5))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(70,50),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(50,22),\n",
    "            nn.Softmax())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        return out\n",
    "\n",
    "    def loss_function(self, *args):\n",
    "        lossF = nn.CrossEntropyLoss()\n",
    "        preds = args[0]\n",
    "        true = args[1]\n",
    "        loss = lossF(preds, true)\n",
    "        return {'loss': loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,\n",
    "                 model: ConvNet1D,\n",
    "                 params: dict) -> None:\n",
    "        super(Experiment, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.params = params\n",
    "        self.curr_device = None\n",
    "        self.hold_graph = False\n",
    "        try:\n",
    "            self.hold_graph = self.params['retain_first_backpass']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def forward(self, input: Tensor, **kwargs) -> Tensor:\n",
    "        return self.model(input, **kwargs)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, optimizer_idx = 0):\n",
    "        real_img, labels = batch\n",
    "        self.curr_device = real_img.device\n",
    "\n",
    "        results = self.forward(real_img, labels = labels)\n",
    "        train_loss = self.model.loss_function(results, labels)\n",
    "\n",
    "        self.log_dict({key: val.item() for key, val in train_loss.items()}, sync_dist=True)\n",
    "\n",
    "        return train_loss['loss']\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, optimizer_idx = 0):\n",
    "        real_img, labels = batch\n",
    "        self.curr_device = real_img.device\n",
    "\n",
    "        results = self.forward(real_img, labels = labels)\n",
    "        val_loss = self.model.loss_function(results, labels)\n",
    "\n",
    "        self.log_dict({f\"val_{key}\": val.item() for key, val in val_loss.items()}, sync_dist=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optims = []\n",
    "        scheds = []\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=self.params['LR'],\n",
    "                               weight_decay=self.params['weight_decay'])\n",
    "        optims.append(optimizer)\n",
    "        # Check if more than 1 optimizer is required (Used for adversarial training)\n",
    "        try:\n",
    "            if self.params['LR_2'] is not None:\n",
    "                optimizer2 = optim.Adam(getattr(self.model,self.params['submodel']).parameters(),\n",
    "                                        lr=self.params['LR_2'])\n",
    "                optims.append(optimizer2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            if self.params['scheduler_gamma'] is not None:\n",
    "                scheduler = optim.lr_scheduler.ExponentialLR(optims[0],\n",
    "                                                             gamma = self.params['scheduler_gamma'])\n",
    "                scheds.append(scheduler)\n",
    "\n",
    "                # Check if another scheduler is required for the second optimizer\n",
    "                try:\n",
    "                    if self.params['scheduler_gamma_2'] is not None:\n",
    "                        scheduler2 = optim.lr_scheduler.ExponentialLR(optims[1],\n",
    "                                                                      gamma = self.params['scheduler_gamma_2'])\n",
    "                        scheds.append(scheduler2)\n",
    "                except:\n",
    "                    pass\n",
    "                return optims, scheds\n",
    "        except:\n",
    "            return optims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class featsDataset(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        ids: list,\n",
    "        feats: dict,\n",
    "        cats: dict,\n",
    "        train_batch_size: int = 8,\n",
    "        val_batch_size: int = 8,\n",
    "        # patch_size: Union[int, Sequence[int]] = (256, 256),\n",
    "        patch_size: int = 64, # Union[int, Sequence[int]] = (256, 256),\n",
    "        num_workers: int = 0,\n",
    "        pin_memory: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.ids = ids,\n",
    "        self.feats = feats,\n",
    "        self.cats = cats,        \n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.pin_memory = pin_memory\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None) -> None:\n",
    "    \n",
    "        train_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "        val_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "        self.train_dataset = ENA6(\n",
    "            self.ids,\n",
    "            self.feats,\n",
    "            self.cats,\n",
    "            transform=train_transforms,\n",
    "        )\n",
    "        \n",
    "        # Replace CelebA with your dataset\n",
    "        self.val_dataset = ENA6(\n",
    "            self.ids,\n",
    "            self.feats,\n",
    "            self.cats,\n",
    "            transform=train_transforms,\n",
    "        )\n",
    "\n",
    "        self.test_dataset = self.val_dataset\n",
    "        \n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.train_batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> Union[DataLoader, List[DataLoader]]:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.val_batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return self.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_params = {\n",
    "  'LR': 0.005,\n",
    "  'weight_decay': 0.0,\n",
    "  'scheduler_gamma': 0.95,\n",
    "  'manual_seed': 1265\n",
    "}\n",
    "\n",
    "class trainer_params:\n",
    "  gpus: 1\n",
    "  max_epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = './log2/'\n",
    "tb_logger =  TensorBoardLogger(save_dir=LOG_DIR,\n",
    "                               name='lightning_logs',)\n",
    "\n",
    "Path(f\"{tb_logger.log_dir}/Samples\").mkdir(exist_ok=True, parents=True)\n",
    "Path(f\"{tb_logger.log_dir}/Reconstructions\").mkdir(exist_ok=True, parents=True)\n",
    "model = ConvNet1D()\n",
    "experiment = Experiment(model,\n",
    "                          exp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "runner = Trainer(callbacks=[\n",
    "                     LearningRateMonitor(),\n",
    "                     ModelCheckpoint(save_top_k=2, \n",
    "                                     dirpath =os.path.join(LOG_DIR , \"checkpoints\"), \n",
    "                                     monitor= \"val_loss\",\n",
    "                                     save_last= True),\n",
    "                 ],\n",
    "                 gpus = 1, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'featsDataset' object has no attribute 'train_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Projects\\wild\\models\\1dcnn.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000015?line=0'>1</a>\u001b[0m datamodule\u001b[39m=\u001b[39m featsDataset(ids\u001b[39m=\u001b[39m[i\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m images], feats \u001b[39m=\u001b[39m data, cats \u001b[39m=\u001b[39m cats)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000015?line=1'>2</a>\u001b[0m datamodule\u001b[39m.\u001b[39;49msetup()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000015?line=2'>3</a>\u001b[0m runner\u001b[39m.\u001b[39mfit(experiment, datamodule\u001b[39m=\u001b[39mdatamodule)\n",
      "\u001b[1;32mc:\\Projects\\wild\\models\\1dcnn.ipynb Cell 10'\u001b[0m in \u001b[0;36mfeatsDataset.setup\u001b[1;34m(self, stage)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=30'>31</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataset \u001b[39m=\u001b[39m ENA6(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=31'>32</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mids,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=32'>33</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeats,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=33'>34</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcats,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=34'>35</a>\u001b[0m     transform\u001b[39m=\u001b[39mtrain_transforms,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=35'>36</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=37'>38</a>\u001b[0m \u001b[39m# Replace CelebA with your dataset\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=38'>39</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_dataset \u001b[39m=\u001b[39m ENA6(\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=39'>40</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=40'>41</a>\u001b[0m     transform\u001b[39m=\u001b[39mtrain_transforms,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=41'>42</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Projects/wild/models/1dcnn.ipynb#ch0000014?line=43'>44</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_dataset\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'featsDataset' object has no attribute 'train_dir'"
     ]
    }
   ],
   "source": [
    "datamodule= featsDataset(ids=[i.split('.jpg')[0] for i in images], feats = data, cats = cats)\n",
    "datamodule.setup()\n",
    "runner.fit(experiment, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 ('wildsenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d488aad3bd47f31cc49211d239eea484ef57a3647b66c4c13e8e3612e9e7defd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
